{
  "git_url": "https://github.com/OCR-D/ocrd_anybaseocr",
  "version": "1.7.0",
  "tools": {
    "ocrd-anybaseocr-binarize": {
      "executable": "ocrd-anybaseocr-binarize",
      "description": "Binarizes images with the algorithm from ocropy and outputs it as an AlternativeImage.",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/binarization"],
      "input_file_grp": ["OCR-D-IMG"],
      "output_file_grp": ["OCR-D-IMG-BIN"],
      "parameters": {
        "nocheck":         {"type": "boolean",                     "default": false, "description": "disable error checking on inputs"},
        "show":            {"type": "boolean",                     "default": false, "description": "display final results"},
        "raw_copy":        {"type": "boolean",                     "default": false, "description": "also copy the raw image"},
        "gray":            {"type": "boolean",                     "default": false, "description": "force grayscale processing even if image seems binary"},
        "bignore":         {"type": "number", "format": "float",   "default": 0.1,   "description": "ignore this much of the border for threshold estimation"},
        "debug":           {"type": "number", "format": "integer", "default": 0,     "description": "display intermediate results"},
        "escale":          {"type": "number", "format": "float",   "default": 1.0,   "description": "scale for estimating a mask over the text region"},
        "hi":              {"type": "number", "format": "float",   "default": 90,    "description": "percentile for white estimation"},
        "lo":              {"type": "number", "format": "float",   "default": 5,     "description": "percentile for black estimation"},
        "perc":            {"type": "number", "format": "float",   "default": 80,    "description": "percentage for filters"},
        "range":           {"type": "number", "format": "integer", "default": 20,    "description": "range for filters"},
        "threshold":       {"type": "number", "format": "float",   "default": 0.5,   "description": "threshold, determines lightness"},
        "zoom":            {"type": "number", "format": "float",   "default": 0.5,   "description": "zoom for page background estimation, smaller=faster"},
        "operation_level": {"type": "string", "enum": ["page","region", "line"], "default": "page","description": "PAGE XML hierarchy level to operate on"}
      }
    },
    "ocrd-anybaseocr-deskew": {
      "executable": "ocrd-anybaseocr-deskew",
      "description": "Deskews images with the algorithm from ocropy and outputs a deskew angle.",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/deskewing"],
      "input_file_grp": ["OCR-D-IMG-BIN"],
      "output_file_grp": ["OCR-D-IMG-DESKEW"],
      "parameters": {
        "escale":    {"type": "number", "format": "float",   "default": 1.0, "description": "scale for estimating a mask over the text region"},
        "bignore":   {"type": "number", "format": "float",   "default": 0.1, "description": "ignore this much of the border for threshold estimation"},
        "threshold": {"type": "number", "format": "float",   "default": 0.5, "description": "threshold, determines lightness"},
        "maxskew":   {"type": "number", "format": "float",   "default": 1.0, "description": "skew angle estimation parameters (degrees)"},
        "skewsteps": {"type": "number", "format": "integer", "default": 8,   "description": "steps for skew angle estimation (per degree)"},
        "debug":     {"type": "number", "format": "integer", "default": 0,   "description": "display intermediate results"},
        "parallel":  {"type": "number", "format": "integer", "default": 0,   "description": "???"},
        "lo":        {"type": "number", "format": "integer", "default": 5,   "description": "percentile for black estimation"},
        "hi":        {"type": "number", "format": "integer", "default": 90,   "description": "percentile for white estimation"},
        "operation_level": {"type": "string", "enum": ["page","region", "line"], "default": "page","description": "PAGE XML hierarchy level to operate on"}
      }
    },
    "ocrd-anybaseocr-crop": {
      "executable": "ocrd-anybaseocr-crop",
      "description": "Detect the input images' page frame, annotate it as border polygon and add a cropped derived image.",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/cropping"],
      "input_file_grp": ["OCR-D-IMG-DESKEW"],
      "output_file_grp": ["OCR-D-IMG-CROP"],
      "parameters": {
        "dpi": {
          "type": "number", "format": "float", "default": 0,
          "description": "pixel density in dots per inch (used to zoom/scale during processing; overrides any meta-data in the images); disabled when zero or negative"},
        "rulerRatioMax": {
          "type": "number", "format": "float", "default": 50.0,
          "description": "ruler detection and suppression: maximum aspect ratio of bbox"},
        "rulerRatioMin": {
          "type": "number", "format": "float", "default": 3.0,
          "description": "ruler detection and suppression: minimum aspect ratio of bbox"},
        "rulerAreaMax":  {
          "type": "number", "format": "float", "default": 0.3,
          "description": "ruler detection and suppression: maximum area of bbox (as ratio of total image pixels)"},
        "rulerAreaMin":  {
          "type": "number", "format": "float", "default": 0.01,
          "description": "ruler detection and suppression: minimum area of bbox (as ratio of total image pixels)"},
        "rulerWidthMax": {
          "type": "number", "format": "float", "default": 0.95,
          "description": "ruler detection and suppression: maximum width of bbox (as ratio of total image width)"},
        "columnAreaMin": {
          "type": "number", "format": "float", "default": 0.05,
          "description": "text block detection: minimum area of individual columns (as ratio of total image pixels)"},
        "columnSepWidthMax": {
          "type": "number", "format": "float", "default": 0.04,
          "description": "text block detection: maximum width between individual columns (as ratio of total image width)"},
        "marginTop": {
          "type": "number", "format": "float", "default": 0.25,
          "description": "ruler / edge / text detection: maximum y position to crop from above (as ratio of total image height)"},
        "marginBottom": {
          "type": "number", "format": "float", "default": 0.75,
          "description": "ruler / edge / text detection: minimum y position to crop from below (as ratio of total image height)"},
        "marginLeft": {
          "type": "number", "format": "float", "default": 0.3,
          "description": "ruler / edge / text detection: maximum x position to crop from left (as ratio of total image width)"},
        "marginRight": {
          "type": "number", "format": "float", "default": 0.7,
          "description": "ruler / edge / text detection: minimum x position to crop from right (as ratio of total image width)"},
        "padding": {
          "type": "number", "format": "integer", "default": 10,
          "description": "extend / shrink border resulting from edge detection / text detection by this many px in each direction"}
      }
    },
    "ocrd-anybaseocr-dewarp": {
      "executable": "ocrd-anybaseocr-dewarp",
      "description": "Dewarps the input image with anyBaseOCR and outputs it as an AlternativeImage",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/dewarping"],
      "input_file_grp": ["OCR-D-IMG-CROP"],
      "output_file_grp": ["OCR-D-IMG-DEWARP"],
      "parameters": {
        "resize_mode": {
          "type": "string",
          "enum": ["resize_and_crop", "crop", "scale_width", "scale_width_and_crop", "none"],
          "default": "resize_and_crop",
          "description": "transformation to apply to the original image before input to the network"
        },
        "resize_height": {
          "type": "number",
          "format": "integer",
          "default": 1024,
          "description": "target image height before input to the network"
        },
        "resize_width": {
          "type": "number",
          "format": "integer",
          "default": 1024,
          "description": "target image width before input to the network"
        },
        "model_path": {
          "type": "string",
          "format": "uri",
          "default": "latest_net_G.pth",
          "description": "Path to the trained pix2pixHD model",
          "cacheable": true,
          "content-type": "application/vnd.pytorch"
        },
        "gpu_id": {
          "type": "number",
          "format": "integer",
          "default": -1,
          "description": "CUDA device ID of GPU to use, or -1 for CPU only"
        },
        "operation_level": {
          "type": "string",
          "enum": ["page", "region"],
          "default": "page",
          "description": "PAGE XML hierarchy level to operate on (should match what model was trained on!)"
        }
      }
    },
    "ocrd-anybaseocr-tiseg": {
      "executable": "ocrd-anybaseocr-tiseg",
      "input_file_grp": ["OCR-D-IMG-CROP"],
      "output_file_grp": ["OCR-D-SEG-TISEG"],
      "categories": ["Layout analysis"],
      "steps": ["layout/segmentation/text-nontext"],
      "description": "Separates the text and non-text elements with anyBaseOCR. Outputs clipped versions of the input image as AlternativeImage containing either only text or non-text elements.",
      "parameters": {
        "use_deeplr": {
          "type":"boolean",
          "default":true,
          "description": "Whether to use deep learning model (UNet pixel classifier) instead of rule-based implementation (multi-resolution morphology)."
        },
        "seg_weights": {
          "type":"string",
          "format":"uri",
          "content-type": "text/directory",
          "cacheable": true,
          "default":"seg_model",
          "description":"Directory path to deep learning model when use_deeplr is true."
        }
      }
    },
    "ocrd-anybaseocr-textline": {
      "executable": "ocrd-anybaseocr-textline",
      "input_file_grp": ["OCR-D-SEG-TISEG"],
      "output_file_grp": ["OCR-D-SEG-LINE-ANY"],
      "categories": ["Layout analysis"],
      "steps": ["layout/segmentation/line"],
      "description": "Finds region polygons for each text line in the input image.",
      "parameters": {
        "minscale":    {"type": "number", "format": "float", "default": 12.0, "description": "minimum scale permitted"},
        "maxlines":    {"type": "number", "format": "float", "default": 300, "description": "non-standard scaling of horizontal parameters"},
        "scale":       {"type": "number", "format": "float", "default": 0.0, "description": "the basic scale of the document (roughly, xheight) 0=automatic"},
        "hscale":      {"type": "number", "format": "float", "default": 1.0, "description": "non-standard scaling of horizontal parameters"},
        "vscale":      {"type": "number", "format": "float", "default": 1.7, "description": "non-standard scaling of vertical parameters"},
        "threshold":   {"type": "number", "format": "float", "default": 0.2, "description": "baseline threshold"},
        "noise":       {"type": "number", "format": "integer", "default": 8, "description": "noise threshold for removing small components from lines"},
        "usegauss":    {"type": "boolean", "default": false, "description": "use gaussian instead of uniform"},
        "maxseps":     {"type": "number", "format": "integer", "default": 2, "description": "maximum black column separators"},
        "sepwiden":    {"type": "number", "format": "integer", "default": 10, "description": "widen black separators (to account for warping)"},
        "blackseps":   {"type": "boolean", "default": false, "description": "also check for black column separators"},
        "maxcolseps":  {"type": "number", "format": "integer", "default": 2, "description": "maximum # whitespace column separators"},
        "csminaspect": {"type": "number", "format": "float", "default": 1.1, "description": "minimum aspect ratio for column separators"},
        "csminheight": {"type": "number", "format": "float", "default": 6.5, "description": "minimum column height (units=scale)"},
        "pad":         {"type": "number", "format": "integer", "default": 3, "description": "padding for extracted lines"},
        "expand":      {"type": "number", "format": "integer", "default": 3, "description": "expand mask for grayscale extraction"},
        "parallel":    {"type": "number", "format": "integer", "default": 0, "description": "number of CPUs to use"},
        "libpath":     {"type": "string", "default": ".", "description": "Library Path for C Executables"},
        "operation_level": {"type": "string", "enum": ["page","region"], "default": "region","description": "PAGE XML hierarchy level to operate on"},
        "overwrite":   {"type": "boolean", "default": false, "description": "check whether to overwrite existing text lines"}
      }
    },
    "ocrd-anybaseocr-layout-analysis": {
      "executable": "ocrd-anybaseocr-layout-analysis",
      "input_file_grp": ["OCR-D-IMG-CROP"],
      "output_file_grp": ["OCR-D-SEG-LAYOUT"],
      "categories": ["Layout analysis"],
      "steps": ["layout/analysis"],
      "description": "Generates a table-of-content like document structure of the whole document.",
      "parameters": {
        "batch_size":         {"type": "number", "format": "integer", "default": 4, "description": "Batch size for generating test images"},
        "model_path":         { "type": "string", "format": "uri", "content-type": "text/directory", "cacheable": true, "default":"structure_analysis", "description": "Directory path to layout structure classification model"},
        "class_mapping_path": { "type": "string", "format": "uri", "content-type": "application/python-pickle", "cacheable": true, "default":"mapping_densenet.pickle", "description": "File path to layout structure classes"}
      }
    },
    "ocrd-anybaseocr-block-segmentation": {
      "executable": "ocrd-anybaseocr-block-segmentation",
      "input_file_grp": ["OCR-D-IMG"],
      "output_file_grp": ["OCR-D-SEG-BLOCK"],
      "categories": ["Layout analysis"],
      "steps": ["layout/segmentation/region"],
      "description": "Segments and classifies regions in each single page and annotates the the region polygons and classes.",
      "parameters": {     
        "block_segmentation_weights": {
	  "type": "string",
          "format":"uri",
          "content-type": "application/x-hdf;subtype=bag",
          "cacheable": true,
	  "default":"block_segmentation_weights.h5",
	  "description": "Path to model weights"
	},
        "overwrite": {
	  "type": "boolean",
	  "default": false,
	  "description": "whether to delete existing text lines prior to segmentation"
	},
        "th": {
	  "type": "integer",
	  "default": 15,
	  "description": "num of pixels to include in the area region (when applying text/non-text mask from tiseg)"
	},
	"active_classes": {
	  "type": "array",
	  "items": {
	    "type": "string",
	    "enum": ["page-number", "paragraph", "catch-word", "heading", "drop-capital", "signature-mark", "header", "marginalia", "footnote", "footnote-continued", "caption", "endnote", "footer", "keynote", "image", "table", "graphics"]
	  },
	  "default": ["page-number", "paragraph", "catch-word", "heading", "drop-capital", "signature-mark", "marginalia", "caption"],
	  "description": "Restrict types of regions to be detected."
	},
        "post_process": {
	  "type": "boolean",
	  "default": true,
	  "description": "whether to apply non-maximum suppression (across classes) on the detections"
	},
        "use_masks": {
	  "type": "boolean",
	  "default": true,
	  "description": "whether to segment from the mask as polygon instead of just the bbox"
	},
        "min_confidence": {
	  "type": "number",
	  "format": "float",
	  "default": 0.9,
	  "description": "Confidence threshold for region detections"
	},
	"min_share_drop": {
	  "type": "number",
	  "format": "float",
	  "default": 0.9,
	  "description": "Minimum required overlap (intersection over single) of mask-derived contour area between neighbours to suppress smaller prediction"
	},
	"min_share_merge": {
	  "type": "number",
	  "format": "float",
	  "default": 0.8,
	  "description": "Minimum required overlap (intersection over single) of mask-derived contour area between neighbours to merge smaller prediction"
	},
	"min_iou_drop": {
	  "type": "number",
	  "format": "float",
	  "default": 0.8,
	  "description": "Minimum required overlap (intersection over union) of mask-derived contour area between neighbours to suppress prediction scoring worse"
	},
	"min_iou_merge": {
	  "type": "number",
	  "format": "float",
	  "default": 0.2,
	  "description": "Minimum required overlap (intersection over union) of mask-derived contour area between neighbours to merge prediction scoring worse"
	}
      }
    }
  }
}
