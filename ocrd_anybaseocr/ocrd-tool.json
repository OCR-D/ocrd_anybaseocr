{
  "git_url": "https://github.com/OCR-D/ocrd_anybaseocr",
  "version": "0.0.3",
  "tools": {
    "ocrd-anybaseocr-binarize": {
      "executable": "ocrd-anybaseocr-binarize",
      "description": "Binarizes images with the algorithm from ocropy and outputs it as an AlternativeImage.",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/binarization"],
      "input_file_grp": ["OCR-D-IMG"],
      "output_file_grp": ["OCR-D-IMG-BIN"],
      "parameters": {
        "force":           {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "nocheck":         {"type": "boolean",                     "default": false, "description": "disable error checking on inputs"},
        "show":            {"type": "boolean",                     "default": false, "description": "display final results"},
        "raw_copy":        {"type": "boolean",                     "default": false, "description": "also copy the raw image"},
        "gray":            {"type": "boolean",                     "default": false, "description": "force grayscale processing even if image seems binary"},
        "bignore":         {"type": "number", "format": "float",   "default": 0.1,   "description": "ignore this much of the border for threshold estimation"},
        "debug":           {"type": "number", "format": "integer", "default": 0,     "description": "display intermediate results"},
        "escale":          {"type": "number", "format": "float",   "default": 1.0,   "description": "scale for estimating a mask over the text region"},
        "hi":              {"type": "number", "format": "float",   "default": 90,    "description": "percentile for white estimation"},
        "lo":              {"type": "number", "format": "float",   "default": 5,     "description": "percentile for black estimation"},
        "perc":            {"type": "number", "format": "float",   "default": 80,    "description": "percentage for filters"},
        "range":           {"type": "number", "format": "integer", "default": 20,    "description": "range for filters"},
        "threshold":       {"type": "number", "format": "float",   "default": 0.5,   "description": "threshold, determines lightness"},
        "zoom":            {"type": "number", "format": "float",   "default": 0.5,   "description": "zoom for page background estimation, smaller=faster"},
        "operation_level": {"type": "string", "enum": ["page","region", "line"], "default": "page","description": "PAGE XML hierarchy level to operate on"}
      }
    },
    "ocrd-anybaseocr-deskew": {
      "executable": "ocrd-anybaseocr-deskew",
      "description": "Deskews images with the algorithm from ocropy and outputs a deskew angle.",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/deskewing"],
      "input_file_grp": ["OCR-D-IMG-BIN"],
      "output_file_grp": ["OCR-D-IMG-DESKEW"],
      "parameters": {
        "force":           {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "escale":    {"type": "number", "format": "float",   "default": 1.0, "description": "scale for estimating a mask over the text region"},
        "bignore":   {"type": "number", "format": "float",   "default": 0.1, "description": "ignore this much of the border for threshold estimation"},
        "threshold": {"type": "number", "format": "float",   "default": 0.5, "description": "threshold, determines lightness"},
        "maxskew":   {"type": "number", "format": "float",   "default": 1.0, "description": "skew angle estimation parameters (degrees)"},
        "skewsteps": {"type": "number", "format": "integer", "default": 8,   "description": "steps for skew angle estimation (per degree)"},
        "debug":     {"type": "number", "format": "integer", "default": 0,   "description": "display intermediate results"},
        "parallel":  {"type": "number", "format": "integer", "default": 0,   "description": "???"},
        "lo":        {"type": "number", "format": "integer", "default": 5,   "description": "percentile for black estimation"},
        "hi":        {"type": "number", "format": "integer", "default": 90,   "description": "percentile for white estimation"},
        "operation_level": {"type": "string", "enum": ["page","region", "line"], "default": "page","description": "PAGE XML hierarchy level to operate on"}
      }
    },
    "ocrd-anybaseocr-crop": {
      "executable": "ocrd-anybaseocr-crop",
      "description": "Crops the input image to the page frame using non-linear processing and outputs a border polygon",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/cropping"],
      "input_file_grp": ["OCR-D-IMG-DESKEW"],
      "output_file_grp": ["OCR-D-IMG-CROP"],
      "parameters": {
        "force"       :  {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "colSeparator":  {"type": "number", "format": "float", "default": 0.04, "description": "consider space between column. 25% of width"},
        "maxRularArea":  {"type": "number", "format": "float", "default": 0.3, "description": "Consider maximum rular area"},
        "minArea":       {"type": "number", "format": "float", "default": 0.05, "description": "rular position in below"},
        "minRularArea":  {"type": "number", "format": "float", "default": 0.01, "description": "Consider minimum rular area"},
        "positionBelow": {"type": "number", "format": "float", "default": 0.75, "description": "rular position in below"},
        "positionLeft":  {"type": "number", "format": "float", "default": 0.4, "description": "rular position in left"},
        "positionRight": {"type": "number", "format": "float", "default": 0.6, "description": "rular position in right"},
        "rularRatioMax": {"type": "number", "format": "float", "default": 10.0, "description": "rular position in below"},
        "rularRatioMin": {"type": "number", "format": "float", "default": 3.0, "description": "rular position in below"},
        "rularWidth":    {"type": "number", "format": "float", "default": 0.95, "description": "maximum rular width"},
        "operation_level": {"type": "string", "enum": ["page"], "default": "page","description": "PAGE XML hierarchy level to operate on"}
      }
    },
    "ocrd-anybaseocr-dewarp": {
      "executable": "ocrd-anybaseocr-dewarp",
      "description": "Dewarps the input image with anyBaseOCR and outputs it as an AlternativeImage",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/dewarping"],
      "input_file_grp": ["OCR-D-IMG-CROP"],
      "output_file_grp": ["OCR-D-IMG-DEWARP"],
      "parameters": {
        "force":        {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "imgresize":    { "type": "string",                     "default": "resize_and_crop", "description": "run on original size image"},
        "model_path":	{ "type": "string", "default": "models/latest_net_G.pth", "description": "Path to the trained pix2pixHD model (Download from https://cloud.dfki.de/owncloud/index.php/s/3zKza5sRfQB3ygy/download)", "cacheable": true, "content-type": "application/vnd.pytorch"},
        "gpu_id":       { "type": "number", "format": "integer", "default": -1,   "description": "device ID of CUDA GPU to use. Set -1 to use CPU only."},
        "resizeHeight": { "type": "number", "format": "integer", "default": 1024, "description": "resized image height"},
        "resizeWidth":  { "type": "number", "format": "integer", "default": 1024, "description": "resized image width"},
        "operation_level": {"type": "string", "enum": ["page","region"], "default": "page","description": "PAGE XML hierarchy level to operate on (should match what model was trained on!)"}
      }
    },
    "ocrd-anybaseocr-tiseg": {
      "executable": "ocrd-anybaseocr-tiseg",
      "input_file_grp": ["OCR-D-IMG-CROP"],
      "output_file_grp": ["OCR-D-SEG-TISEG"],
      "categories": ["Layout analysis"],
      "steps": ["layout/segmentation/text-image"],
      "description": "Separates the text and non-text elements with anyBaseOCR. Outputs clipped versions of the input image as AlternativeImage containing either only text or non-text elements.",
      "parameters": {
        "force":           {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "use_deeplr":      {"type":"boolean",                      "default":true, "description": "use deep learning model"},
        "seg_weights":     {"type":"string",                       "default":"models/seg_model.hdf5", "description":"path to weights file", "required":false},
         "classes":        {"type":"integer",                      "default":3, "description":"number of classes" },
         "width"  :        {"type":"integer",                      "default":1024, "description":"input image height"},
         "height" :        {"type":"integer",                      "default":800, "description":"input image width"},
        "operation_level": {"type": "string", "enum": ["page","region", "line"], "default": "page","description": "PAGE XML hierarchy level to operate on"}
      }
    },
    "ocrd-anybaseocr-textline": {
      "executable": "ocrd-anybaseocr-textline",
      "input_file_grp": ["OCR-D-SEG-TISEG"],
      "output_file_grp": ["OCR-D-SEG-LINE-ANY"],
      "categories": ["Layout analysis"],
      "steps": ["layout/segmentation/line"],
      "description": "Finds region polygons for each text line in the input image.",
      "parameters": {
        "force":           {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "minscale":    {"type": "number", "format": "float", "default": 12.0, "description": "minimum scale permitted"},
        "maxlines":    {"type": "number", "format": "float", "default": 300, "description": "non-standard scaling of horizontal parameters"},
        "scale":       {"type": "number", "format": "float", "default": 0.0, "description": "the basic scale of the document (roughly, xheight) 0=automatic"},
        "hscale":      {"type": "number", "format": "float", "default": 1.0, "description": "non-standard scaling of horizontal parameters"},
        "vscale":      {"type": "number", "format": "float", "default": 1.7, "description": "non-standard scaling of vertical parameters"},
        "threshold":   {"type": "number", "format": "float", "default": 0.2, "description": "baseline threshold"},
        "noise":       {"type": "number", "format": "integer", "default": 8, "description": "noise threshold for removing small components from lines"},
        "usegauss":    {"type": "boolean", "default": false, "description": "use gaussian instead of uniform"},
        "maxseps":     {"type": "number", "format": "integer", "default": 2, "description": "maximum black column separators"},
        "sepwiden":    {"type": "number", "format": "integer", "default": 10, "description": "widen black separators (to account for warping)"},
        "blackseps":   {"type": "boolean", "default": false, "description": "also check for black column separators"},
        "maxcolseps":  {"type": "number", "format": "integer", "default": 2, "description": "maximum # whitespace column separators"},
        "csminaspect": {"type": "number", "format": "float", "default": 1.1, "description": "minimum aspect ratio for column separators"},
        "csminheight": {"type": "number", "format": "float", "default": 6.5, "description": "minimum column height (units=scale)"},
        "pad":         {"type": "number", "format": "integer", "default": 3, "description": "padding for extracted lines"},
        "expand":      {"type": "number", "format": "integer", "default": 3, "description": "expand mask for grayscale extraction"},
        "parallel":    {"type": "number", "format": "integer", "default": 0, "description": "number of CPUs to use"},
        "libpath":     {"type": "string", "default": ".", "description": "Library Path for C Executables"},
        "operation_level": {"type": "string", "enum": ["page","region"], "default": "region","description": "PAGE XML hierarchy level to operate on"},
        "overwrite":   {"type": "boolean", "default": false, "description": "check whether to overwrite existing text lines"}
      }
    },
    "ocrd-anybaseocr-layout-analysis": {
      "executable": "ocrd-anybaseocr-layout-analysis",
      "input_file_grp": ["OCR-D-IMG-CROP"],
      "output_file_grp": ["OCR-D-SEG-LAYOUT"],
      "categories": ["Layout analysis"],
      "steps": ["layout/segmentation/text-image"],
      "description": "Generates a table-of-content like document structure of the whole document.",
      "parameters": {
        "force":           {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "batch_size":         {"type": "number", "format": "integer", "default": 4, "description": "Batch size for generating test images"},
        "model_path":         { "type": "string", "default":"models/structure_analysis.h5", "required": false, "description": "Path to Layout Structure Classification Model"},
        "class_mapping_path": { "type": "string", "default":"models/mapping_densenet.pickle","required": false, "description": "Path to Layout Structure Classes"}
      }
    },
    "ocrd-anybaseocr-block-segmentation": {
      "executable": "ocrd-anybaseocr-block-segmentation",
      "input_file_grp": ["OCR-D-IMG"],
      "output_file_grp": ["OCR-D-BLOCK-SEGMENT"],
      "categories": ["Layout analysis"],
      "steps": ["layout/segmentation/text-image"],
      "description": "Segments and classifies document segments in a single page and outputs the the region polygons and classes.",
      "parameters": {     
        "force":           {"type":"boolean",                      "default":true, "description": "overwrite existing files"},
        "block_segmentation_model":   { "type": "string","default":"mrcnn/", "required": false, "description": "Path to block segmentation Model"},
        "block_segmentation_weights": { "type": "string","default":"models/block_segmentation_weights.h5",  "required": false, "description": "Path to model weights"},
        "operation_level": {"type": "string", "enum": ["page"], "default": "page","description": "PAGE XML hierarchy level to operate on"},
        "overwrite":   {"type": "boolean", "default": false, "description": "check whether to overwrite existing text lines"},
        "th"       :   {"type": "integer", "default": 15, "descrption": "num of pixels to include in the area region"},
        "DETECTION_MIN_CONFIDENCE"       :   {"type": "number", "default": 0.9, "descrption": "Confidence value for a model to detect bounding box"}
      }       
    }
  }
}
